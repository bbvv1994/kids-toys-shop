#!/bin/bash

# ðŸ—“ï¸ Ð£Ð»ÑƒÑ‡ÑˆÐµÐ½Ð½Ñ‹Ð¹ ÐµÐ¶ÐµÐ½ÐµÐ´ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð±ÑÐºÐ°Ð¿ Ð½Ð° Google Drive Ñ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ¾Ð¹ Cloudinary
# Ð­Ñ‚Ð¾Ñ‚ ÑÐºÑ€Ð¸Ð¿Ñ‚ ÑÐ¾Ð·Ð´Ð°ÐµÑ‚ Ð¿Ð¾Ð»Ð½Ñ‹Ð¹ Ð±ÑÐºÐ°Ð¿ Ð¸ Ð·Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÑ‚ ÐµÐ³Ð¾ Ð½Ð° Google Drive
# ÐŸÐ¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÑ‚ ÐºÐ°Ðº Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ñ‹Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ, Ñ‚Ð°Ðº Ð¸ Cloudinary URL

set -e

# Ð¦Ð²ÐµÑ‚Ð° Ð´Ð»Ñ Ð²Ñ‹Ð²Ð¾Ð´Ð°
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

log() {
    echo -e "${GREEN}[$(date +'%Y-%m-%d %H:%M:%S')] $1${NC}"
}

error() {
    echo -e "${RED}[ERROR] $1${NC}"
    exit 1
}

warning() {
    echo -e "${YELLOW}[WARNING] $1${NC}"
}

info() {
    echo -e "${BLUE}[INFO] $1${NC}"
}

# ÐŸÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ
BACKUP_DIR="/home/kids-toys/backups"
GOOGLE_DRIVE_DIR="/home/kids-toys/google-drive-backup"
APP_DIR="/home/kids-toys/app"
DATE=$(date +%Y%m%d_%H%M%S)
WEEK=$(date +%Y-W%U)

log "ðŸ—“ï¸ ÐÐ°Ñ‡Ð°Ð»Ð¾ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð½Ð¾Ð³Ð¾ ÐµÐ¶ÐµÐ½ÐµÐ´ÐµÐ»ÑŒÐ½Ð¾Ð³Ð¾ Ð±ÑÐºÐ°Ð¿Ð°"
log "ðŸ“… Ð”Ð°Ñ‚Ð°: $(date)"
log "ðŸ“Š ÐÐµÐ´ÐµÐ»Ñ: $WEEK"
log "â˜ï¸ ÐŸÐ¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ°: Ð›Ð¾ÐºÐ°Ð»ÑŒÐ½Ñ‹Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ + Cloudinary URL"

# Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¸ Ð´Ð»Ñ Ð±ÑÐºÐ°Ð¿Ð°
mkdir -p $BACKUP_DIR

# 1. Ð‘ÑÐºÐ°Ð¿ Ð±Ð°Ð·Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ… (Ð²ÐºÐ»ÑŽÑ‡Ð°Ñ Ð²ÑÐµ imageUrls)
log "ðŸ“Š Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð±ÑÐºÐ°Ð¿Ð° Ð±Ð°Ð·Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ…..."
DB_BACKUP_FILE="$BACKUP_DIR/db_backup_$DATE.sql"
sudo -u postgres pg_dump kids_toys_db > $DB_BACKUP_FILE

if [ -f "$DB_BACKUP_FILE" ] && [ -s "$DB_BACKUP_FILE" ]; then
    log "âœ… Ð‘ÑÐºÐ°Ð¿ Ð±Ð°Ð·Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ… ÑÐ¾Ð·Ð´Ð°Ð½: $(du -h $DB_BACKUP_FILE | cut -f1)"
    
    # ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ Ñ‚Ð¸Ð¿Ñ‹ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹ Ð² Ð±Ð°Ð·Ðµ Ð´Ð°Ð½Ð½Ñ‹Ñ…
    log "ðŸ” ÐÐ½Ð°Ð»Ð¸Ð· Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹ Ð² Ð±Ð°Ð·Ðµ Ð´Ð°Ð½Ð½Ñ‹Ñ…..."
    CLOUDINARY_COUNT=$(grep -o 'https://res.cloudinary.com' "$DB_BACKUP_FILE" | wc -l || echo "0")
    LOCAL_COUNT=$(grep -o '/uploads/' "$DB_BACKUP_FILE" | wc -l || echo "0")
    
    log "ðŸ“Š Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹ Ð² Ð‘Ð”:"
    log "   - Cloudinary URL: $CLOUDINARY_COUNT"
    log "   - Ð›Ð¾ÐºÐ°Ð»ÑŒÐ½Ñ‹Ðµ Ð¿ÑƒÑ‚Ð¸: $LOCAL_COUNT"
else
    error "âŒ ÐžÑˆÐ¸Ð±ÐºÐ° ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ Ð±ÑÐºÐ°Ð¿Ð° Ð±Ð°Ð·Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ…"
fi

# 2. Ð‘ÑÐºÐ°Ð¿ Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹ (Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¸Ð· Ð¿Ð°Ð¿ÐºÐ¸ uploads)
log "ðŸ–¼ï¸ Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð±ÑÐºÐ°Ð¿Ð° Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹..."
UPLOADS_BACKUP_FILE="$BACKUP_DIR/uploads_backup_$DATE.tar.gz"

if [ -d "$APP_DIR/uploads" ]; then
    # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð°Ñ€Ñ…Ð¸Ð² Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹
    tar -czf $UPLOADS_BACKUP_FILE -C $APP_DIR uploads/
    
    if [ -f "$UPLOADS_BACKUP_FILE" ] && [ -s "$UPLOADS_BACKUP_FILE" ]; then
        UPLOADS_SIZE=$(du -h $UPLOADS_BACKUP_FILE | cut -f1)
        UPLOADS_COUNT=$(tar -tzf $UPLOADS_BACKUP_FILE | wc -l)
        log "âœ… Ð‘ÑÐºÐ°Ð¿ Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹ ÑÐ¾Ð·Ð´Ð°Ð½: $UPLOADS_SIZE ($UPLOADS_COUNT Ñ„Ð°Ð¹Ð»Ð¾Ð²)"
    else
        error "âŒ ÐžÑˆÐ¸Ð±ÐºÐ° ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ Ð±ÑÐºÐ°Ð¿Ð° Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹"
    fi
else
    warning "âš ï¸ ÐŸÐ°Ð¿ÐºÐ° uploads Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð°, ÑÐ¾Ð·Ð´Ð°ÐµÐ¼ Ð¿ÑƒÑÑ‚Ð¾Ð¹ Ð°Ñ€Ñ…Ð¸Ð²"
    tar -czf $UPLOADS_BACKUP_FILE -T /dev/null
fi

# 3. Ð‘ÑÐºÐ°Ð¿ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¸ (Ð²ÐºÐ»ÑŽÑ‡Ð°Ñ Cloudinary Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸)
log "âš™ï¸ Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð±ÑÐºÐ°Ð¿Ð° ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¸..."
CONFIG_BACKUP_FILE="$BACKUP_DIR/config_backup_$DATE.tar.gz"

# Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½ÑƒÑŽ Ð¿Ð°Ð¿ÐºÑƒ Ð´Ð»Ñ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¸
TEMP_CONFIG_DIR="/tmp/config_backup_$DATE"
mkdir -p "$TEMP_CONFIG_DIR"

# ÐšÐ¾Ð¿Ð¸Ñ€ÑƒÐµÐ¼ Ð¾ÑÐ½Ð¾Ð²Ð½Ñ‹Ðµ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¾Ð½Ð½Ñ‹Ðµ Ñ„Ð°Ð¹Ð»Ñ‹
cp "$APP_DIR/backend/.env" "$TEMP_CONFIG_DIR/" 2>/dev/null || true
cp -r "$APP_DIR/backend/prisma/" "$TEMP_CONFIG_DIR/" 2>/dev/null || true

# Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ñ„Ð°Ð¹Ð» Ñ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÐµÐ¹ Ð¾ Cloudinary
cat > "$TEMP_CONFIG_DIR/cloudinary_info.txt" << EOF
Cloudinary Configuration Information
====================================
Date: $(date)
Backup Type: Enhanced with Cloudinary support

Database contains:
- Cloudinary URLs: $CLOUDINARY_COUNT
- Local image paths: $LOCAL_COUNT

Image Storage Strategy:
- Cloudinary URLs are stored directly in database
- Local images are backed up separately
- On restore: Cloudinary images load automatically
- Local images are restored from uploads backup

Cloudinary URLs format:
- https://res.cloudinary.com/[cloud_name]/image/upload/[public_id].[format]

Local paths format:
- /uploads/[filename]
EOF

# ÐÑ€Ñ…Ð¸Ð²Ð¸Ñ€ÑƒÐµÐ¼ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸ÑŽ
tar -czf $CONFIG_BACKUP_FILE -C /tmp "config_backup_$DATE"

# ÐžÑ‡Ð¸Ñ‰Ð°ÐµÐ¼ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½ÑƒÑŽ Ð¿Ð°Ð¿ÐºÑƒ
rm -rf "$TEMP_CONFIG_DIR"

if [ -f "$CONFIG_BACKUP_FILE" ] && [ -s "$CONFIG_BACKUP_FILE" ]; then
    log "âœ… Ð‘ÑÐºÐ°Ð¿ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¸ ÑÐ¾Ð·Ð´Ð°Ð½: $(du -h $CONFIG_BACKUP_FILE | cut -f1)"
else
    error "âŒ ÐžÑˆÐ¸Ð±ÐºÐ° ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ Ð±ÑÐºÐ°Ð¿Ð° ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¸"
fi

# 4. Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð¿Ð¾Ð»Ð½Ð¾Ð³Ð¾ Ð°Ñ€Ñ…Ð¸Ð²Ð°
log "ðŸ“¦ Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð¿Ð¾Ð»Ð½Ð¾Ð³Ð¾ Ð°Ñ€Ñ…Ð¸Ð²Ð°..."
FULL_BACKUP_FILE="$BACKUP_DIR/full_backup_$WEEK.tar.gz"
tar -czf $FULL_BACKUP_FILE -C $BACKUP_DIR db_backup_$DATE.sql uploads_backup_$DATE.tar.gz config_backup_$DATE.tar.gz

if [ -f "$FULL_BACKUP_FILE" ] && [ -s "$FULL_BACKUP_FILE" ]; then
    log "âœ… ÐŸÐ¾Ð»Ð½Ñ‹Ð¹ Ð°Ñ€Ñ…Ð¸Ð² ÑÐ¾Ð·Ð´Ð°Ð½: $(du -h $FULL_BACKUP_FILE | cut -f1)"
else
    error "âŒ ÐžÑˆÐ¸Ð±ÐºÐ° ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ Ð¿Ð¾Ð»Ð½Ð¾Ð³Ð¾ Ð°Ñ€Ñ…Ð¸Ð²Ð°"
fi

# 5. Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð½Ð° Google Drive Ñ‡ÐµÑ€ÐµÐ· OAuth 2.0
log "â˜ï¸ Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð½Ð° Google Drive (OAuth 2.0)..."
cd $GOOGLE_DRIVE_DIR

# ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð½Ð°Ð»Ð¸Ñ‡Ð¸Ðµ Ñ‚Ð¾ÐºÐµÐ½Ð°
if [ ! -f "token.pickle" ]; then
    error "âŒ Ð¢Ð¾ÐºÐµÐ½ Ð°ÑƒÑ‚ÐµÐ½Ñ‚Ð¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ð¸ (token.pickle) Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½!"
    error "Ð—Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚Ðµ python3 enter_auth_code_new_client.py Ð´Ð»Ñ Ð°ÑƒÑ‚ÐµÐ½Ñ‚Ð¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ð¸"
fi

# Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð¿Ð¾Ð»Ð½Ñ‹Ð¹ Ð°Ñ€Ñ…Ð¸Ð²
python3 upload_to_drive.py "$FULL_BACKUP_FILE" "kids-toys-full-backup-$WEEK.tar.gz"

# Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ñ„Ð°Ð¹Ð»Ñ‹
python3 upload_to_drive.py "$DB_BACKUP_FILE" "db_backup_$DATE.sql"
python3 upload_to_drive.py "$UPLOADS_BACKUP_FILE" "uploads_backup_$DATE.tar.gz"
python3 upload_to_drive.py "$CONFIG_BACKUP_FILE" "config_backup_$DATE.tar.gz"

# 6. ÐžÑ‡Ð¸ÑÑ‚ÐºÐ° ÑÑ‚Ð°Ñ€Ñ‹Ñ… Ð±ÑÐºÐ°Ð¿Ð¾Ð² (ÑÑ‚Ð°Ñ€ÑˆÐµ 30 Ð´Ð½ÐµÐ¹)
log "ðŸ§¹ ÐžÑ‡Ð¸ÑÑ‚ÐºÐ° ÑÑ‚Ð°Ñ€Ñ‹Ñ… Ð±ÑÐºÐ°Ð¿Ð¾Ð²..."
find $BACKUP_DIR -name "*.sql" -mtime +30 -delete
find $BACKUP_DIR -name "*.tar.gz" -mtime +30 -delete

log "âœ… Ð£Ð»ÑƒÑ‡ÑˆÐµÐ½Ð½Ñ‹Ð¹ ÐµÐ¶ÐµÐ½ÐµÐ´ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð±ÑÐºÐ°Ð¿ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½!"
log "ðŸ“Š Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°:"
echo "   - Ð‘Ð°Ð·Ð° Ð´Ð°Ð½Ð½Ñ‹Ñ…: $(du -h $DB_BACKUP_FILE | cut -f1)"
echo "   - Ð›Ð¾ÐºÐ°Ð»ÑŒÐ½Ñ‹Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ: $(du -h $UPLOADS_BACKUP_FILE | cut -f1) ($UPLOADS_COUNT Ñ„Ð°Ð¹Ð»Ð¾Ð²)"
echo "   - ÐšÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ñ: $(du -h $CONFIG_BACKUP_FILE | cut -f1)"
echo "   - ÐŸÐ¾Ð»Ð½Ñ‹Ð¹ Ð°Ñ€Ñ…Ð¸Ð²: $(du -h $FULL_BACKUP_FILE | cut -f1)"
echo "   - Cloudinary URL Ð² Ð‘Ð”: $CLOUDINARY_COUNT"
echo "   - Ð›Ð¾ÐºÐ°Ð»ÑŒÐ½Ñ‹Ðµ Ð¿ÑƒÑ‚Ð¸ Ð² Ð‘Ð”: $LOCAL_COUNT"
echo "   - Ð’ÑÐµÐ³Ð¾ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð¾ Ð² Google Drive: 4 Ñ„Ð°Ð¹Ð»Ð°"

log "ðŸŽ‰ Ð‘ÑÐºÐ°Ð¿ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½!"
log "ðŸ’¡ ÐŸÑ€Ð¸ Ð²Ð¾ÑÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ð¸:"
log "   - Cloudinary Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð·Ð°Ð³Ñ€ÑƒÐ·ÑÑ‚ÑÑ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸"
log "   - Ð›Ð¾ÐºÐ°Ð»ÑŒÐ½Ñ‹Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð²Ð¾ÑÑÑ‚Ð°Ð½Ð¾Ð²ÑÑ‚ÑÑ Ð¸Ð· uploads backup"

